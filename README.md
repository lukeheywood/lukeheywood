# ONE â€” GitHub Front Door

### Coherence, Governance, and Systems That Hold Under Load

Hi, Iâ€™m Luke. I design and build AI-enabled systems that stay **coherent, inspectable, and governed** under real-world complexity.

This GitHub is the **front door** to the ONE system â€” a personal AI operating system built around memory, workflows, diagnostics, and explicit constraints.

This is not a product showcase.
Itâ€™s a **working system** with clear boundaries, runnable engines, and enforceable limits.

---

## ğŸ§­ The System at a Glance

ONE is intentionally split across a small number of repositories, each with a single, explicit role:

### ğŸ§± one-platform â€” *Canonical Truth*

The authoritative system map.

* System Atlas (what exists, what runs, whatâ€™s partial)
* Codex (design rationale and intent)
* Contracts index and governance surfaces
* Canonical case studies and evidence

If you want to understand **what ONE is and why itâ€™s shaped this way**, start here.

ğŸ‘‰ [https://github.com/lukeheywood/one-platform](https://github.com/lukeheywood/one-platform)

---

### âš™ï¸ one-runtime â€” *Runnable Public Mirror*

The system you can actually run.

* Memory OS, Autopilot, Meta OS, Orchestrator, Control Tower UI
* Governed workflows and inspection tooling
* Fixture-driven, fully reconstructable
* Zero private data, zero personal state

This repo proves the system works â€” safely and inspectably.

ğŸ‘‰ [https://github.com/lukeheywood/one-runtime](https://github.com/lukeheywood/one-runtime)

---

### ğŸ›¡ï¸ contract-stack â€” *Governance Authority*

The rules that bind the system.

* Formal contracts and admissibility rules
* Regression and coherence gates
* Enforcement utilities used by the runtime

If `one-runtime` shows **how** the system runs,
`contract-stack` defines **where it must stop**.

ğŸ‘‰ [https://github.com/lukeheywood/contract-stack](https://github.com/lukeheywood/contract-stack)

---

### ğŸ›ï¸ ai â€” system â€” design â€” governance *System-Level Standard*

The governing framework that sits above any individual AI system.

System-level AI System Design & Governance framework

Defines what must be true before, during, and after an AI system exists

Separates governance from implementation to avoid circular authority

Designed to apply to any AI-enabled socio-technical system, not just ONE

This repository acts as the constitutional layer:

it defines scope, authority, unacceptable states, and enforcement posture

it does not contain runtime code

it does not depend on ONE or any other system

AI systems (including ONE) sit inside this framework and may be inspected against it.

ğŸ‘‰ https://github.com/lukeheywood/ai-system-design-governance

---

### ğŸ” system-diagnostics â€” *Drift & Failure Patterns*

Supporting patterns for understanding why systems degrade over time.

* Drift detection
* Competing intents
* Hidden coupling
* Quiet failure modes

This repo is not canonical, but it reflects how I reason about failure in complex platforms.

ğŸ‘‰ [https://github.com/lukeheywood/system-diagnostics](https://github.com/lukeheywood/system-diagnostics)

---

## ğŸ§  The Lens

Across all of this work, a few principles stay fixed:

* **Coherence under load**
  Systems must remain understandable even as complexity and pressure increase.

* **Governance by design**
  Constraints, invariants, and contracts prevent slow drift.

* **AI as pipelines, not prompts**
  LLMs are components inside workflows, not autonomous decision-makers.

* **Explicit limits and abstention**
  A system that knows when it must stop is safer than one that always answers.

* **Inspection over vibes**
  What exists, what runs, and whatâ€™s missing should be visible in black and white.

---

## ğŸ“š About Other Repositories

You may notice additional archived or experimental repositories on this account.

These are preserved for historical reference, pattern extraction, or prior exploration.
They are **not authoritative** and are intentionally de-emphasized.

The active system is represented by the repositories above.

---

## âœï¸ Authorship & Responsibility

ONE is an authored system.

I am its designer and take responsibility for its behavior, limits, and failure modes as it evolves.

Its assumptions are explicit.
Its constraints are intentional.
Its gaps are named, not obscured.

This work is built in public so it can be examined directly.

---

If youâ€™re interested in:

* AI systems that donâ€™t quietly drift,
* governance that actually constrains behavior,
* or making complex platforms legible again,

youâ€™re in the right place.
